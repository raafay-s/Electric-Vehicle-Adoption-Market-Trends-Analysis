import pandas as pd
from google.colab import files

# Upload the raw EV dataset from your computer
uploaded = files.upload()

# Read the uploaded CSV file into a DataFrame
df = pd.read_csv("EV_Data.csv")

# Drop unnecessary columns often generated by spreadsheets or redundant totals
df = df.drop(columns=["Unnamed: 0", "Unnamed: 0.1", "Total"], errors="ignore")

# Rename all columns to a consistent snake_case format to make them easier to reference in code
df.columns = [
    "state", "year", "ev_registrations", "total_vehicles", "ev_share_percent",
    "stations", "total_charging_outlets", "level_1", "level_2", "dc_fast",
    "fuel_economy", "incentives", "metro_orgs", "population_20_64",
    "education_bachelor", "labour_force_participation_rate",
    "unemployment_rate", "bachelor_attainment", "per_cap_income",
    "affectweather", "devharm", "discuss", "exp", "localofficials",
    "personal", "reducetax", "regulate", "worried", "price_cents_per_kwh",
    "gasoline_price_per_gallon", "trucks", "trucks_share", "party"
]

# Convert percentage columns from string to float, forcing any invalid values to NaN
df["ev_share_percent"] = pd.to_numeric(df["ev_share_percent"], errors="coerce")
df["trucks_share"] = pd.to_numeric(df["trucks_share"], errors="coerce")

# Define all numeric columns so we can safely convert them in bulk
numeric_cols = [
    "ev_registrations", "total_vehicles", "stations", "total_charging_outlets",
    "level_1", "level_2", "dc_fast", "fuel_economy", "metro_orgs",
    "population_20_64", "education_bachelor", "labour_force_participation_rate",
    "unemployment_rate", "bachelor_attainment", "per_cap_income",
    "affectweather", "devharm", "discuss", "exp", "localofficials", "personal",
    "reducetax", "regulate", "worried", "price_cents_per_kwh",
    "gasoline_price_per_gallon", "trucks"
]

# Convert all numeric columns to numeric types; if any value is invalid, it becomes NaN. This ensures all numeric data is properly typed and ready for SQL
df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, errors="coerce")

# Drop rows where all values are missing, to remove completely empty records
df = df.dropna(how="all")

# Drop rows with too many missing values; we keep only rows where at least 90% of columns are filled
df = df.dropna(thresh=int(0.9 * len(df.columns)))

# Sort the dataset by state and year to make trends easier to analyze and visualize
df = df.sort_values(by=["state", "year"])

# Save the cleaned dataset to a new CSV file
df.to_csv("EV_Data_Cleaned.csv", index=False)

# Downloads the cleaned CSV file
files.download("EV_Data_Cleaned.csv")
